{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6067bdcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T17:43:23.184640Z",
     "start_time": "2024-07-08T17:43:22.996866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/biobombe/0.expression-download\n"
     ]
    }
   ],
   "source": [
    "# To install the grein_loader package\n",
    "#!pip install grein_loader\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "331a0f21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T16:54:48.746158Z",
     "start_time": "2024-07-12T16:54:48.387365Z"
    }
   },
   "outputs": [],
   "source": [
    "import grein_loader as loader\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "269899538ef2705f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T20:55:03.754179Z",
     "start_time": "2024-07-08T20:55:03.751498Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load log file from disk to see if this data has already been added\n",
    "def load_log(logFile):\n",
    "    log = pd.read_csv(logFile, names=[\"GSE\", \"status\"])\n",
    "    log = log[log[\"status\"] == \"end\"]\n",
    "    return set(log[\"GSE\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7c098d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T17:13:13.465724Z",
     "start_time": "2024-07-12T17:13:08.745057Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading grein overview\n",
    "\n",
    "# loading a subset of the data\n",
    "# number_of_datasets = 1000\n",
    "# overview = loader.load_overview(number_of_datasets)\n",
    "\n",
    "# loading all the data\n",
    "overview = loader.load_overview(5)\n",
    "\n",
    "# Accessing the geo_accession ID and study species from overview\n",
    "geo_accession_ids = []\n",
    "species = []\n",
    "for i in range(len(overview)):\n",
    "    geo_accession_ids.append(overview[i]['geo_accession'])\n",
    "    species.append(overview[i]['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4df223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the species in each GSE\n",
    "GSE_species = {'geo_accession_id': geo_accession_ids, 'species': species}\n",
    "GSE_species_df = pd.DataFrame.from_dict(GSE_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5e31d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_accession_id</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSE100007</td>\n",
       "      <td>Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSE100027</td>\n",
       "      <td>Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSE100040</td>\n",
       "      <td>Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSE100075</td>\n",
       "      <td>Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSE100081</td>\n",
       "      <td>Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20359</th>\n",
       "      <td>GSE131512</td>\n",
       "      <td>Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20360</th>\n",
       "      <td>GSE226189</td>\n",
       "      <td>Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20361</th>\n",
       "      <td>GSE131990</td>\n",
       "      <td>Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20362</th>\n",
       "      <td>GSE132204</td>\n",
       "      <td>Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20363</th>\n",
       "      <td>GSE132024</td>\n",
       "      <td>Homo sapiens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20364 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      geo_accession_id       species\n",
       "0            GSE100007  Homo sapiens\n",
       "1            GSE100027  Homo sapiens\n",
       "2            GSE100040  Homo sapiens\n",
       "3            GSE100075  Homo sapiens\n",
       "4            GSE100081  Homo sapiens\n",
       "...                ...           ...\n",
       "20359        GSE131512  Homo sapiens\n",
       "20360        GSE226189  Homo sapiens\n",
       "20361        GSE131990  Homo sapiens\n",
       "20362        GSE132204  Homo sapiens\n",
       "20363        GSE132024  Homo sapiens\n",
       "\n",
       "[20364 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading gene expression data filtered by species using the geo_accession IDs\n",
    "# NOTE this does not save/pickle the description or metadata at all\n",
    "\n",
    "GSE_species_df_filtered = GSE_species_df[GSE_species_df['species'] == 'Homo sapiens']\n",
    "\n",
    "GSE_species_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cefa7777",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core.numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/micromamba/envs/biobombe/lib/python3.12/site-packages/pandas/io/pickle.py:202\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    201\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[0;32m--> 202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core.numeric'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Saving human gene expression data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Check if there is already data downloaded or whether we are starting fresh\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreinLoadHuman.log\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownload/grein_count_matrix_human.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m): \n\u001b[0;32m----> 5\u001b[0m     count_matrix_human_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdownload/grein_count_matrix_human.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     completed \u001b[38;5;241m=\u001b[39m load_log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuman\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/biobombe/lib/python3.12/site-packages/pandas/io/pickle.py:207\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/micromamba/envs/biobombe/lib/python3.12/site-packages/pandas/compat/pickle_compat.py:231\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# \"Unpickler\" has no attribute \"is_verbose\"  [attr-defined]\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     up\u001b[38;5;241m.\u001b[39mis_verbose \u001b[38;5;241m=\u001b[39m is_verbose  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/biobombe/lib/python3.12/pickle.py:1205\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1203\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1205\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/micromamba/envs/biobombe/lib/python3.12/pickle.py:1530\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/micromamba/envs/biobombe/lib/python3.12/site-packages/pandas/compat/pickle_compat.py:162\u001b[0m, in \u001b[0;36mUnpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m    160\u001b[0m key \u001b[38;5;241m=\u001b[39m (module, name)\n\u001b[1;32m    161\u001b[0m module, name \u001b[38;5;241m=\u001b[39m _class_locations_map\u001b[38;5;241m.\u001b[39mget(key, key)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/biobombe/lib/python3.12/pickle.py:1572\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING:\n\u001b[1;32m   1571\u001b[0m         module \u001b[38;5;241m=\u001b[39m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[0;32m-> 1572\u001b[0m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core.numeric'"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m********* |\u001B[39m\u001B[38;5;124m\"\u001B[39m, geo_accession, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m| ***********\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     12\u001B[0m logfile\u001B[38;5;241m.\u001B[39mwrite(geo_accession \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,start\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 14\u001B[0m count_matrix_human_df \u001B[38;5;241m=\u001B[39m load_data(geo_accession, count_matrix_human_df)\n\u001B[1;32m     16\u001B[0m logfile\u001B[38;5;241m.\u001B[39mwrite(geo_accession \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,write\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     17\u001B[0m count_matrix_human_df\u001B[38;5;241m.\u001B[39mto_pickle(humanData)\n",
      "Cell \u001B[0;32mIn[16], line 2\u001B[0m, in \u001B[0;36mload_data\u001B[0;34m(geo_accession, count_matrix_df)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_data\u001B[39m(geo_accession, count_matrix_df):\n\u001B[0;32m----> 2\u001B[0m     description, metadata, count_matrix \u001B[38;5;241m=\u001B[39m loader\u001B[38;5;241m.\u001B[39mload_dataset(geo_accession)\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m# Merge in to existing count matrix DF\u001B[39;00m\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m count_matrix_df\u001B[38;5;241m.\u001B[39mempty:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/grein_loader/load_dataset.py:83\u001B[0m, in \u001B[0;36mload_dataset\u001B[0;34m(gse_id, download_type)\u001B[0m\n\u001B[1;32m     81\u001B[0m config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     82\u001B[0m ACK_flag \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m---> 83\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m lines:\n\u001B[1;32m     84\u001B[0m     line_content \u001B[38;5;241m=\u001B[39m line\u001B[38;5;241m.\u001B[39mdecode()\n\u001B[1;32m     85\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m line_content\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma[\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0#0|m|\u001B[39m\u001B[38;5;124m'\u001B[39m):  \u001B[38;5;66;03m# search for config parameter to parse sessionId\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/requests/models.py:869\u001B[0m, in \u001B[0;36mResponse.iter_lines\u001B[0;34m(self, chunk_size, decode_unicode, delimiter)\u001B[0m\n\u001B[1;32m    860\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001B[39;00m\n\u001B[1;32m    861\u001B[0m \u001B[38;5;124;03mstream=True is set on the request, this avoids reading the\u001B[39;00m\n\u001B[1;32m    862\u001B[0m \u001B[38;5;124;03mcontent at once into memory for large responses.\u001B[39;00m\n\u001B[1;32m    863\u001B[0m \n\u001B[1;32m    864\u001B[0m \u001B[38;5;124;03m.. note:: This method is not reentrant safe.\u001B[39;00m\n\u001B[1;32m    865\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    867\u001B[0m pending \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 869\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miter_content(\n\u001B[1;32m    870\u001B[0m     chunk_size\u001B[38;5;241m=\u001B[39mchunk_size, decode_unicode\u001B[38;5;241m=\u001B[39mdecode_unicode\n\u001B[1;32m    871\u001B[0m ):\n\u001B[1;32m    872\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m pending \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    873\u001B[0m         chunk \u001B[38;5;241m=\u001B[39m pending \u001B[38;5;241m+\u001B[39m chunk\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/requests/models.py:820\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    818\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    819\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 820\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    821\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    822\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/response.py:1040\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m   1024\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1025\u001B[0m \u001B[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001B[39;00m\n\u001B[1;32m   1026\u001B[0m \u001B[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1037\u001B[0m \u001B[38;5;124;03m    'content-encoding' header.\u001B[39;00m\n\u001B[1;32m   1038\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1039\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunked \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupports_chunked_reads():\n\u001B[0;32m-> 1040\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread_chunked(amt, decode_content\u001B[38;5;241m=\u001B[39mdecode_content)\n\u001B[1;32m   1041\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1042\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/response.py:1184\u001B[0m, in \u001B[0;36mHTTPResponse.read_chunked\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m   1181\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1183\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1184\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_chunk_length()\n\u001B[1;32m   1185\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunk_left \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1186\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/response.py:1108\u001B[0m, in \u001B[0;36mHTTPResponse._update_chunk_length\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunk_left \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1108\u001B[0m line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mfp\u001B[38;5;241m.\u001B[39mreadline()  \u001B[38;5;66;03m# type: ignore[union-attr]\u001B[39;00m\n\u001B[1;32m   1109\u001B[0m line \u001B[38;5;241m=\u001B[39m line\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m;\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1110\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/socket.py:706\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    704\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 706\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39mrecv_into(b)\n\u001B[1;32m    707\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    708\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Saving human gene expression data\n",
    "with open(humanLog, \"a\") as logfile:\n",
    "    for geo_accession in GSE_species_df_filtered['geo_accession_id']:\n",
    "        \n",
    "        # Check if this data was logged as loaded\n",
    "        if geo_accession in completed:\n",
    "            print(\"Already done: {0}\".format(geo_accession))\n",
    "            continue\n",
    "            \n",
    "        # If new data, download data and add to df\n",
    "        print(\"********* |\", geo_accession, \"| ***********\")\n",
    "        logfile.write(geo_accession + \",start\\n\")\n",
    "        \n",
    "        # Merge in to existing count matrix DF\n",
    "        if count_matrix_human_df.empty:\n",
    "            count_matrix_human_df = count_matrix\n",
    "        else:\n",
    "            count_matrix_human_df = pd.merge(count_matrix_human_df, count_matrix,  how='left', on=[\"gene\", \"gene_symbol\"], suffixes = None)\n",
    "        \n",
    "        logfile.write(geo_accession + \",write\\n\")\n",
    "        count_matrix_human_df.to_pickle(humanData)\n",
    "        logfile.write(geo_accession + \",end\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                  gene   gene_symbol  GSM2667747  GSM2667748  GSM2667749  \\\n0      ENSG00000000003        TSPAN6   1766.0677    420.8206    300.8009   \n1      ENSG00000000005          TNMD     43.9280     18.0091      0.0000   \n2      ENSG00000000419          DPM1   1097.7855    367.2333    316.5226   \n3      ENSG00000000457         SCYL3    601.4702    270.9239    163.6869   \n4      ENSG00000000460      C1orf112   1040.8861    349.1418    298.1800   \n...                ...           ...         ...         ...         ...   \n27985  ENSG00000283688      MIR6715B      0.0000      0.0000      0.0000   \n27986  ENSG00000283690     MIR3116-2      0.0000      0.0000      0.0000   \n27987  ENSG00000283694     MIR3202-2      0.0000      0.0000      0.0000   \n27988  ENSG00000283697  LOC101928917      1.7315      0.0000      0.0000   \n27989  ENSG00000283699       MIR4481      0.0000      1.1301      0.0000   \n\n       GSM2667750  GSM2667751  GSM2667752  GSM2667753  GSM2667754  ...  \\\n0       3142.8439   2207.8392   4367.5056    228.5759    650.3287  ...   \n1        115.8917     63.5936     39.7803     11.7588      1.0153  ...   \n2       3895.0588   1536.1375   1084.5276    127.7205    245.1014  ...   \n3       1177.2241    873.9074    845.1423    229.8548    134.4694  ...   \n4       1967.3975   2115.2425    980.9359    253.4457    145.7038  ...   \n...           ...         ...         ...         ...         ...  ...   \n27985      0.0000      0.0000      0.0000      0.0000      0.0000  ...   \n27986      0.0000      0.0000      0.0000      0.0000      0.0000  ...   \n27987      0.0000      0.0000      0.0000      0.0000      0.0000  ...   \n27988      0.0000      2.0039      3.9899      2.5184      4.1298  ...   \n27989      1.3192      0.0000      0.0000      0.0000      0.0000  ...   \n\n       GSM2668086  GSM2668087  GSM2668088  GSM2668089  GSM2671001  GSM2671002  \\\n0        254.7605    143.2263    174.3319    202.3253   1053.8788   2405.3001   \n1          0.0000      0.0000      0.0000      0.0000      3.9978     11.0025   \n2        613.1214    374.0965    302.6622    454.0570   1227.1084   2980.0756   \n3        196.5995    185.3106    260.9485    183.7584    586.7993   1504.0115   \n4        204.1681    186.2225    127.6457    172.0572    441.0758   1258.3932   \n...           ...         ...         ...         ...         ...         ...   \n27985      0.0000      0.0000      0.0000      0.0000      0.0000      0.0000   \n27986      0.0000      0.0000      0.0000      0.0000      0.0000      0.0000   \n27987      0.0000      0.0000      0.0000      0.0000      0.0000      0.0000   \n27988         NaN         NaN         NaN         NaN         NaN         NaN   \n27989      0.0000      0.0000      0.0000      0.0000      0.9935      0.0000   \n\n       GSM2671003  GSM2671004  GSM2671005  GSM2671006  \n0        940.5770    973.7475    760.0100   1472.2712  \n1          4.9979      8.0054      3.9978     11.0011  \n2       1045.8061   1098.7163    759.7729   1398.8077  \n3        619.3764    661.9514    469.5312   1113.1412  \n4        466.5542    450.2848    289.2767    467.7875  \n...           ...         ...         ...         ...  \n27985      0.0000      0.0000      0.0000      0.0000  \n27986      0.0000      0.0000      0.0000      0.0000  \n27987      0.0000      0.0000      0.0000      0.0000  \n27988         NaN         NaN         NaN         NaN  \n27989      0.0000      3.0216      1.0072      0.0000  \n\n[27990 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gene</th>\n      <th>gene_symbol</th>\n      <th>GSM2667747</th>\n      <th>GSM2667748</th>\n      <th>GSM2667749</th>\n      <th>GSM2667750</th>\n      <th>GSM2667751</th>\n      <th>GSM2667752</th>\n      <th>GSM2667753</th>\n      <th>GSM2667754</th>\n      <th>...</th>\n      <th>GSM2668086</th>\n      <th>GSM2668087</th>\n      <th>GSM2668088</th>\n      <th>GSM2668089</th>\n      <th>GSM2671001</th>\n      <th>GSM2671002</th>\n      <th>GSM2671003</th>\n      <th>GSM2671004</th>\n      <th>GSM2671005</th>\n      <th>GSM2671006</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ENSG00000000003</td>\n      <td>TSPAN6</td>\n      <td>1766.0677</td>\n      <td>420.8206</td>\n      <td>300.8009</td>\n      <td>3142.8439</td>\n      <td>2207.8392</td>\n      <td>4367.5056</td>\n      <td>228.5759</td>\n      <td>650.3287</td>\n      <td>...</td>\n      <td>254.7605</td>\n      <td>143.2263</td>\n      <td>174.3319</td>\n      <td>202.3253</td>\n      <td>1053.8788</td>\n      <td>2405.3001</td>\n      <td>940.5770</td>\n      <td>973.7475</td>\n      <td>760.0100</td>\n      <td>1472.2712</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENSG00000000005</td>\n      <td>TNMD</td>\n      <td>43.9280</td>\n      <td>18.0091</td>\n      <td>0.0000</td>\n      <td>115.8917</td>\n      <td>63.5936</td>\n      <td>39.7803</td>\n      <td>11.7588</td>\n      <td>1.0153</td>\n      <td>...</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>3.9978</td>\n      <td>11.0025</td>\n      <td>4.9979</td>\n      <td>8.0054</td>\n      <td>3.9978</td>\n      <td>11.0011</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ENSG00000000419</td>\n      <td>DPM1</td>\n      <td>1097.7855</td>\n      <td>367.2333</td>\n      <td>316.5226</td>\n      <td>3895.0588</td>\n      <td>1536.1375</td>\n      <td>1084.5276</td>\n      <td>127.7205</td>\n      <td>245.1014</td>\n      <td>...</td>\n      <td>613.1214</td>\n      <td>374.0965</td>\n      <td>302.6622</td>\n      <td>454.0570</td>\n      <td>1227.1084</td>\n      <td>2980.0756</td>\n      <td>1045.8061</td>\n      <td>1098.7163</td>\n      <td>759.7729</td>\n      <td>1398.8077</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ENSG00000000457</td>\n      <td>SCYL3</td>\n      <td>601.4702</td>\n      <td>270.9239</td>\n      <td>163.6869</td>\n      <td>1177.2241</td>\n      <td>873.9074</td>\n      <td>845.1423</td>\n      <td>229.8548</td>\n      <td>134.4694</td>\n      <td>...</td>\n      <td>196.5995</td>\n      <td>185.3106</td>\n      <td>260.9485</td>\n      <td>183.7584</td>\n      <td>586.7993</td>\n      <td>1504.0115</td>\n      <td>619.3764</td>\n      <td>661.9514</td>\n      <td>469.5312</td>\n      <td>1113.1412</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENSG00000000460</td>\n      <td>C1orf112</td>\n      <td>1040.8861</td>\n      <td>349.1418</td>\n      <td>298.1800</td>\n      <td>1967.3975</td>\n      <td>2115.2425</td>\n      <td>980.9359</td>\n      <td>253.4457</td>\n      <td>145.7038</td>\n      <td>...</td>\n      <td>204.1681</td>\n      <td>186.2225</td>\n      <td>127.6457</td>\n      <td>172.0572</td>\n      <td>441.0758</td>\n      <td>1258.3932</td>\n      <td>466.5542</td>\n      <td>450.2848</td>\n      <td>289.2767</td>\n      <td>467.7875</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27985</th>\n      <td>ENSG00000283688</td>\n      <td>MIR6715B</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>...</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>27986</th>\n      <td>ENSG00000283690</td>\n      <td>MIR3116-2</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>...</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>27987</th>\n      <td>ENSG00000283694</td>\n      <td>MIR3202-2</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>...</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>27988</th>\n      <td>ENSG00000283697</td>\n      <td>LOC101928917</td>\n      <td>1.7315</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>2.0039</td>\n      <td>3.9899</td>\n      <td>2.5184</td>\n      <td>4.1298</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27989</th>\n      <td>ENSG00000283699</td>\n      <td>MIR4481</td>\n      <td>0.0000</td>\n      <td>1.1301</td>\n      <td>0.0000</td>\n      <td>1.3192</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>...</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.9935</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>3.0216</td>\n      <td>1.0072</td>\n      <td>0.0000</td>\n    </tr>\n  </tbody>\n</table>\n<p>27990 rows × 57 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(humanData)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T17:12:04.989606Z",
     "start_time": "2024-07-12T17:12:04.931187Z"
    }
   },
   "id": "8035da339504313c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* | GSE100007 | ***********\n",
      "********* | GSE100027 | ***********\n",
      "********* | GSE100040 | ***********\n",
      "********* | GSE100075 | ***********\n",
      "********* | GSE100081 | ***********\n",
      "********* | GSE100092 | ***********\n",
      "********* | GSE100099 | ***********\n",
      "********* | GSE100118 | ***********\n",
      "********* | GSE100183 | ***********\n",
      "********* | GSE100206 | ***********\n",
      "********* | GSE100210 | ***********\n",
      "********* | GSE100223 | ***********\n",
      "********* | GSE100258 | ***********\n",
      "********* | GSE100266 | ***********\n",
      "********* | GSE100268 | ***********\n",
      "********* | GSE100291 | ***********\n",
      "********* | GSE100297 | ***********\n",
      "********* | GSE100327 | ***********\n",
      "********* | GSE100338 | ***********\n",
      "********* | GSE100359 | ***********\n",
      "********* | GSE100382 | ***********\n",
      "********* | GSE100392 | ***********\n",
      "********* | GSE100408 | ***********\n",
      "********* | GSE100417 | ***********\n",
      "********* | GSE100427 | ***********\n",
      "********* | GSE100501 | ***********\n",
      "********* | GSE100520 | ***********\n",
      "********* | GSE100530 | ***********\n",
      "********* | GSE100562 | ***********\n",
      "********* | GSE100568 | ***********\n"
     ]
    }
   ],
   "source": [
    "# Saving mice gene expression data\n",
    "\n",
    "# Check if there is already data downloaded or whether we are starting fresh\n",
    "if os.path.exists(\"greinLoadMice.log\") and os.path.exists(\"download/grein_count_matrix_mice.pkl\"): \n",
    "    count_matrix_human_df = pd.read_pickle(\"download/grein_count_matrix_mice.pkl\")\n",
    "    completed = load_log(\"Mice\")\n",
    "\n",
    "else:\n",
    "    count_matrix_mice_df = pd.DataFrame()\n",
    "    completed = set()\n",
    "    os.system(\"touch greinLoadMice.log\")\n",
    "\n",
    "with open(\"greinLoadMice.log\", \"a\") as logfile:\n",
    "    for geo_accession in geo_accession_ids:\n",
    "        \n",
    "        # Check if this data was succesfully pickled\n",
    "        if geo_accession in completed:\n",
    "            continue\n",
    "            \n",
    "        # If new data, download data and add to df\n",
    "        print(\"********* |\", geo_accession, \"| ***********\")\n",
    "        logfile.write(geo_accession + \",start\\n\")\n",
    "        description, metadata, count_matrix = loader.load_dataset(geo_accession)\n",
    "        # print(\"Description: \", description)\n",
    "        \n",
    "        # Merge in to existing count matrix DF\n",
    "        if count_matrix_human_df.empty:\n",
    "            count_matrix_human_df = count_matrix\n",
    "        else:\n",
    "            count_matrix_human_df = pd.merge(count_matrix_human_df, count_matrix,  how='left', on=[\"gene\", \"gene_symbol\"])\n",
    "        \n",
    "        logfile.write(geo_accession + \",write\\n\")\n",
    "        count_matrix_human_df.to_pickle(\"download/grein_count_matrix_human.pkl\")\n",
    "        logfile.write(geo_accession + \",end\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(\"download/grein_count_matrix_human.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c48bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from the data sets using the geo_accession IDs\n",
    "# NOTE this does not save/pickle the description or metadata at all\n",
    "\n",
    "with open(\"greinLoad.log\", \"a\") as logfile:\n",
    "    for geo_accession in geo_accession_ids:\n",
    "        \n",
    "        # Check if this data was succesfully pickled\n",
    "        if geo_accession in completed:\n",
    "            continue\n",
    "            \n",
    "        # If new data, download data and add to df\n",
    "        print(\"********* |\", geo_accession, \"| ***********\")\n",
    "        logfile.write(geo_accession + \",start\\n\")\n",
    "        description, metadata, count_matrix = loader.load_dataset(geo_accession)\n",
    "        # print(\"Description: \", description)\n",
    "        \n",
    "        # Merge in to existing count matrix DF\n",
    "        if count_matrix_df.empty:\n",
    "            count_matrix_df = count_matrix\n",
    "        else:\n",
    "            count_matrix_df = pd.merge(count_matrix_df, count_matrix,  how='left', on=[\"gene\", \"gene_symbol\"])\n",
    "        \n",
    "        logfile.write(geo_accession + \",write\\n\")\n",
    "        count_matrix_df.to_pickle(\"download/grein_count_matrix.pkl\")\n",
    "        logfile.write(geo_accession + \",end\\n\")\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab50fdd-e162-4f5f-8382-7a96c93c5902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timimg the loading of data sets\n",
    "start = time.time()\n",
    "print(loader.load_overview(10))\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d59c22",
   "metadata": {},
   "source": [
    "## Save the data loaded above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba973b3",
   "metadata": {},
   "source": [
    "**Count_matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dda5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(), 'download', 'count_matrix.tsv')\n",
    "with open(path, 'w') as file:\n",
    "    count_matrix_df.to_csv(path, sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e5023",
   "metadata": {},
   "source": [
    "**Description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15f8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save description. Currently saves description for only one data set at a time\n",
    "path = os.path.join('download', 'description.json')\n",
    "with open(path, 'w') as file:\n",
    "    # Serialize and write the variable to the file\n",
    "    json.dump(description, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724557b3",
   "metadata": {},
   "source": [
    "**Metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec21cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from metadata\n",
    "metadata_df = pd.DataFrame.from_dict(metadata)\n",
    "\n",
    "# list of row names in metadata_df\n",
    "row_names = list(metadata_df.index)\n",
    "\n",
    "# Creating a list of rows that we do not require to process this data set\n",
    "unneeded_rows = ['Consent', ' ', 'channel_count', 'organism_ch1', 'relation', 'status']\n",
    "for index in row_names:\n",
    "    if ('contact' in index) or ('date' in index) or ('data_processing' in index) or ('Hash' in index) or ('Date' in index) or ('library' in index):\n",
    "        unneeded_rows.append(index)\n",
    "        \n",
    "# remove unnecessary roles from count_matrix\n",
    "metadata_df.drop(unneeded_rows, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab20d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b031d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b543432",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
